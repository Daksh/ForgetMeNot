<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="forgetmenot-exploring-accidental-linkability-of-users">ForgetMeNot: Exploring Accidental Linkability of Users</h1>
<h2 id="a-case-study-on-github-stackoverflow-and-twitter">A case study on GitHub, StackOverflow, and Twitter</h2>
<h2 id="our-team">Our Team</h2>
<p><img src="https://i.imgur.com/tdUpaCy.png" alt="Imgur"></p>
<h2 id="introduction">Introduction</h2>
<p>Online Social Networks (OSNs) have experienced exponential growth in recent years. They have a significant presence in both the personal and professional lives of a vast segment of the world's populace.
Any content or personal information that an individual shares on any social network can be traced back to him/her even after it has been removed. It is rightly said that 'Nothing is ever lost on the internet.'</p>
<p>Unsurprisingly, OSNs are subject to severe privacy and security risks. Due to the amount of personally identifiable information shared by users in OSNs and lack of adequate privacy settings, it becomes possible to aggregate data about users by linking their profiles across several online social networks.</p>
<p>For our project, we decided to explore this accidental linkability by exploiting privacy and security issues associated with users' OSNs and behavioral tendencies.</p>
<p>We started with accessing publicly available data, collecting personally identifiable information (PII) on the users, followed by varied attempts to link them to accounts on different OSNs.</p>
<h2 id="timeline">Timeline</h2>
<p><img src="https://i.imgur.com/WjlFHE4.jpg" alt="Imgur"></p>
<h2 id="initial-idea-exploring-accidental-release-of-api-keys">Initial Idea: Exploring accidental release of API Keys</h2>
<p>While doing the assignments in this course, we noticed that many developers on Github forget to remove API keys (for their social network accounts such as Twitter and Slack). To confirm this, we manually searched GitHub and found some lists of Twitter API keys. After curating them together, we were able to get roughly 300 unique Twitter API keys, out of which around 200 were valid and working keys. The problem was fascinating since there were a lot of security and privacy-related aspects to it. These keys could be used to collect more data per unit time (for networks that throttle with rate limits per account). More interestingly, in some cases, can give a stranger complete access to another user's Twitter account (which would be a gross breach of security and privacy). Hence, we decided to attempt at extracting such API keys from GitHub commits (and StackOverflow data).</p>
<p>Initially, we used a regex of Slack API keys to find such keys in the GitHub commits and StackOverflow data. Once we got these API keys, we needed a way to test them and use them. Hence we set up a terminal utility (written in Golang). This utility took the Slack API key as input and opened a terminal interface for that user. Using this, we had complete control over the user's account where we could even send messages from the account. This was a gross breach of security and privacy that we were able to exploit. Here's an example:
<img src="https://i.imgur.com/G4GSutP.jpg" alt="Imgur"></p>
<h2 id="github-email-vulnerability">GitHub Email Vulnerability</h2>
<p>When setting up <code>git</code> for the first time on your laptop/machine, a user is required to set a Name and an Email before making a commit. These are generally set by a command similar to <code>git config --global user.email &quot;email@example.com&quot;</code>. Users often do not wonder about the repercussions; this may have a few years later in the future. For example, when pushing commits to your public repository on GitHub, you are attaching this set name+email (in plaintext) along with.</p>
<p>Don't take our word for it. Test it out!</p>
<ol>
<li>Clone any public repository (eg. <code>git clone https://github.com/Daksh/process-github-daily-dumps.git</code>)</li>
<li>Navigate inside this repository using terminal (eg. <code>cd process-github-daily-dumps</code>)</li>
<li>Check the commits using <code>git log</code>
<img src="https://i.imgur.com/Cp4TlDY.png" alt="github_email_in_commit"></li>
</ol>
<p>Voila! You will find the user mentioned email address along with each commit.</p>
<p>We decided to use this interesting observation to see the magnitude of this potentially unintentional breach of privacy. To operationalize this experiment, We downloaded daily dumps of GitHub data for May and June (2019). Each daily-dump was about 5-7 GB's on average in its zipped form. Due to computational restrictions, processing the data was a challenge for us. To overcome this difficulty, we automated the following steps of the process:</p>
<ul>
<li>Download the daily dump (<code>.zip</code>)</li>
<li>Extract the <code>.bson</code> files from the zip</li>
<li>Import select <code>.bson</code> files to the Mongo database</li>
<li>Run a <code>.py</code> script to extract information from the Mongo database</li>
<li>Cleanup</li>
</ul>
<p><strong>We have publically released this automation code on Github, at <a href="https://github.com/Daksh/process-github-daily-dumps">https://github.com/Daksh/process-github-daily-dumps</a>.</strong></p>
<p>The following information on the users was collected from the data mentioned above:</p>
<ul>
<li>Github Profile</li>
<li>Name</li>
<li>Organisation</li>
<li>Email</li>
<li>Avatar</li>
<li>Site Admin Status</li>
</ul>
<h2 id="stackoverflow-email-and-phone-number-vulnerability">StackOverflow Email and Phone Number Vulnerability</h2>
<p>StackOverflow releases its complete data regularly. We used one of these dumps from <a href="https://archive.org/details/stackexchange">https://archive.org/details/stackexchange</a>, and processed the &quot;About Me&quot; section of users.</p>
<p>Often users put out their emails and phone numbers in their About Me, hoping for humans looking at their profile to be able to reach out to them. This opens them to the possibility of a script being able to gather all such data and potentially misuse it.</p>
<p>We found the following PII(s):</p>
<ul>
<li>StackOverflow Profile</li>
<li>Name</li>
<li>Email (9,411 email ids)</li>
<li>Phone Number (933 phone numbers)</li>
<li>Avatar [Profile Photo]</li>
</ul>
<h2 id="using-the-collected-data">Using the Collected Data</h2>
<p>From the data collected above, we decided to make use of the email ids of users and find the possible social media platforms on which their accounts can be linked. We started with an exploration of the information we could get for a user using their email on platforms like LinkedIn, Twitter, Facebook, and Instagram.</p>
<h3 id="linkedin-sales-api">LinkedIn Sales API</h3>
<p>We came across an old chrome extension <code>Rapportive</code> which would return the <strong>LinkedIn</strong> profile for given email id (provided that an associated LinkedIn account exists).</p>
<p>We found out that this extension was eventually acquired by LinkedIn and integrated into their sales API. Then, we looked at the documentation of their API and found that the CURL request for the sales API was of the form:</p>
<blockquote>
<p><code>https://www.linkedin.com/sales/gmail/profile/viewByEmail/</code></p>
</blockquote>
<p>We opened this given URL directly in our browser upon suffixing it by a valid email:</p>
<blockquote>
<p><code>https://www.linkedin.com/sales/gmail/profile/viewByEmail/abc@gmail.com</code></p>
</blockquote>
<p>The resulting webpage looked like the following:</p>
<p><img src="https://i.imgur.com/RtttPTh.png" alt="SalesAPI"></p>
<p>We decided to proceed by scraping data from the page that was returned by this URL. However, we encountered another challenge. For the above request to work, we needed to be logged into a LinkedIn account, which wasn't feasible while using a scraper programmatically.</p>
<p>To overcome this, we used Burp Suite - it acts as a Man in the Middle (MITM) between our web browser and the internet. We used it to analyze the GET request made to the above URL. We could now repeat the same request with the same headers but different payload (email) to get user information. As only authenticated LinkedIn users are allowed to use this API, we needed authentication tokens (from headers) to automate the whole process (using Burp Suite).</p>
<p><img src="https://i.imgur.com/TWJeknm.png" alt="BurpSuite"></p>
<p>From the output, we scraped the entire HTML and parsed it to collect more information. In addition to their LinkedIn Profiles, we also collect the following information:</p>
<ul>
<li>Profile Photo</li>
<li>Job Title</li>
<li>Organization</li>
<li>Location</li>
<li>Other links (Twitter, Facebook etc.)</li>
</ul>
<p>While we had started collecting data using this methodology, shortly after, the <strong>LinkedIn Sales API</strong> feature was sunset. Hence, we could only obtain the information for a subset of the users in our dataset.</p>
<p><img src="https://i.imgur.com/jpb1pXm.png" alt="SalesAPISunset"></p>
<h3 id="analysis">Analysis</h3>
<p>We made an <strong>Image Grid</strong> to get an understanding if the profiles collected are genuine or not.</p>
<p>Note: There did not exist a tool to create such an interactive grid, hence we wrote the script ourselves. <strong>We have publically released this tool on Github, (at <a href="https://github.com/Daksh/Interactive-Image-Grid">https://github.com/Daksh/Interactive-Image-Grid</a>).</strong></p>
<iframe id="imageGrid" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/linkedIn_profile_images_grid_web.html" height="525" width="100%"></iframe>
<p>We made <strong>Word Clouds</strong> to see the most prominent working titles of users and organizations where they worked at:</p>
<p><img src="https://i.imgur.com/f5jQwNm.png" alt="Title"> <img src="https://i.imgur.com/nYmmWQm.png" alt="Org"></p>
<p>We also plotted the locations of the users on a Map to profile our demographic further.</p>
<p><img src="https://i.imgur.com/S87TmDt.png" alt="Imgur"></p>
<p>We scraped links to other platforms from a user's Linekdin profile and found the following distribution of linked platforms through the LinkedIn Data:</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/LinkedInData.html" height="525" width="100%"></iframe>
<h2 id="syncing-google-contacts">Syncing Google Contacts</h2>
<p>To try and link accounts on more online platforms, we decided to make use of the <code>Sync Contacts</code> feature on popular OSM's such as Facebook, Instagram, and Twitter.</p>
<p>We made VCFs (virtual contact file) containing names and email ids for a significant proportion of users in our data and added them to a newly created dummy Google Account. The first difficulty we faced here was that Google Contacts only allowed adding a limited number of contacts at a time despite the limit being 25k.</p>
<p>When we tried syncing these contacts on Facebook, Instagram, and Twitter, we ran into the following problems:</p>
<ul>
<li><strong>Facebook</strong> - Post syncing of the contacts, we did get suggestions for people in our contact list. However, they also contained other random people from outside our contacts. Another challenge here was that the output page only loaded a limited number of profiles at a time and required scrolling the page to load more results. This wasn't programmatically possible.</li>
<li><strong>Instagram</strong> - Earlier Instagram had a feature where one could sync their Google Contacts and follow them on Instagram, but that feature did not exist anymore. Even after syncing the contacts, the suggestions were minimal and mixed.</li>
<li><strong>Twitter</strong> - Despite successfully syncing the contacts, Twitter could not find the profile of people in our contact list or suggest their twitter accounts.</li>
</ul>
<p>As a result, we were not successful in this approach.</p>
<h2 id="getting-to-know-our-github-users-more">Getting to know our GitHub users more</h2>
<p>To extend our PII search on GitHub, we scraped the profiles of the users whose emails we found in the GitHub Daily Dumps. Upon doing this, we got to know these fields about each of the users:</p>
<ul>
<li>Personal URL</li>
<li>Location</li>
<li>Organization</li>
<li>Bio</li>
</ul>
<p>To avoid getting blacklisted by GitHub (or overload them with too many requests), we sent a throtlled number and hence we were able to do this process for 32k/1.6m users.</p>
<h2 id="finding-linkability-on-twitter">Finding linkability on Twitter</h2>
<p>We came across an interesting Twitter trend, where users post tweets asking for their followers' profiles on other social networks. They ask for various profiles such as Instagram, Soundcloud, Paypal, etc. so they could add them as friends on that platform, promote their content, or donate small amounts of money to them (e.g. paying for their lunch).</p>
<p><img src="https://i.imgur.com/uHxRLOW.png" alt="twitter_data"></p>
<h3 id="data-collection">Data Collection</h3>
<p>We decided to collect this data by querying searches of the form&quot; <code>drop your &lt;platform_name&gt;</code>&quot; on Twitter. We considered the following platforms for the collection of this data:</p>
<ul>
<li>Instagram</li>
<li>Snapchat</li>
<li>Spotify</li>
<li>Soundcloud</li>
<li>Venmo</li>
<li>Paypal</li>
</ul>
<p>We used Twint (an advanced Twitter scraping tool written in python) to retrieve tweets using such queries.</p>
<p>Interestingly, we noticed an increased number of such tweets since lockdowns (commenced due to COVID). We did a time-series analysis on all tweets containing our queries to confirm the same.</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/TweetTimeSeries.html" height="525" width="100%"></iframe>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/TweetTimeSeriesCF.html" height="525" width="100%"></iframe>
<p>As visible from the graph, there is an increase in the slope post the commencement of lockdown periods in countries majorly affected by COVID, denoting higher usage periods of social media in those countries due to reduced in-person interactions. We also plotted the locations of these users:</p>
<p><img src="https://i.imgur.com/V7X9Y4f.png" alt="Imgur"></p>
<p>Once such tweets were retrieved, we decided to use the Twitter API to get the replies to such tweets. The twitter API itself does not have a feature for querying replies to a tweet. We worked our way around by querying the mentions of the users who posted the original tweet and checking if those mentions were in replies to the tweets we initially stored. However, this only gave us recent mention-containing tweets (due to the API endpoint restrictions). Because of this, we were restricted to scraping tweets only from the past 24 hours.</p>
<p>We continued collecting this data for five days and got good results.
For Snapchat, we retrieved the snapcodes that users had shared instead of any Snapchat links in the replies. These snapcodes are unique to only one profile and hence can be considered as PII for a user. Following is a collage of the snapcodes we collected from the images embedded in replies to the tweets:</p>
<p><img src="https://i.imgur.com/7xWQpht.jpg" alt="snapchat_collage"></p>
<p>We parsed the collected replies for possible links of their accounts on these platforms. While parsing these, we also collected any URLs that the users had linked in their profile or bio to enable linking to more platforms. This process yielded the following distribution of linked platforms:</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/TwitterReplies.html" height="525" width="100%"></iframe>
<p><strong>The graph shows that in just five days, we were able to collect around 15,000 social network profiles for different Twitter users</strong>. If this process of scraping tweet replies is carried out over a longer time, we expect to have link a sizable number of Twitter users to at least one other social network, if not more.</p>
<h3 id="insights">Insights</h3>
<p>We plotted a graph with the followers and following of the users who were the ones replying to such tweets:</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/FollowerFollowing.html" height="525" width="100%"></iframe>
<ul>
<li>Top 5% of the Users have 10.5k or more followers.</li>
<li>Top 25% of the Users have 1.5k or more followers.</li>
<li>Proportion of Users with low # of followers is more than Users with a high # of followers.</li>
</ul>
<p>We found an interesting platform <strong>Linktree</strong>, which was linked to the twitter profiles of such users. Linktree allows users to curate a one-stop page to connect all their OSN accounts. Here, we noticed users adding all their social media links so that their audience can access them on one page.</p>
<p><img src="https://i.imgur.com/nPnJYhT.png" alt="linktree"></p>
<p>We found no previous research on this platform and read online that it comprises of roughly 3 million users. We feel that this platform might be ideal for future research on linkability since it has no limits on scraping and compromises the links to multiple user accounts.</p>
<h2 id="conclusion--evaluation">Conclusion + Evaluation</h2>
<p>This graph represents all the users we were able to link via Twitter replies and it gives the distribution of the number of platforms we were able to link them on:</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/LinkabilityTwitter.html" height="525" width="100%"></iframe>
<p>This graph represents all the users we were able to link via their LinkedIn profiles, which were found out by using their email ids retrieved from StackOverflow and a part of GitHub data, and it gives the distribution of the number of platforms we were able to link them on:</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/LinkabilityLinkedIn.html" height="525" width="100%"></iframe>
<p>This graph is a cumulative representation of all the users we were able to link via different source platforms, and it gives the distribution of the number of platforms we were able to link them on. We were unable to process all the GitHub data to find the LinkedIn profiles for users since the LinkedIn sales API was sunset soon after we discovered it, and hence the unprocessed GitHub data has been represented separately:</p>
<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://ashwin-19.github.io/Media%20(Blog)/Linkability.html" height="525" width="100%"></iframe>
<p>We can see that it is straightforward to link a user on two platforms, but it keeps getting tougher to link the user on more platforms.</p>
<p>In 3 months with limited resources, we were able to link roughly 1.7 million user profiles across a minimum of 2 platforms and a maximum of 5 platforms from a tiny part of publically available data on the internet. It is very clear from the dataset that we have been able to create, that users are often careless with what they share online and most likely forget about all the personal information that they have put out there. It has become easy to link one person on a particular platform to other profiles on different OSNs. This makes it possible to profile an individual and hence breach his/her privacy and security online.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S2468696417300332%60">https://www.sciencedirect.com/science/article/abs/pii/S2468696417300332`</a></li>
<li><a href="https://ieeexplore.ieee.org/abstract/document/5510913?casa_token=hYekQX0-bnIAAAAA:TIlYOLsXVRkH26cMlJC3ZRyP1LxsEGBSnkNGqCVwu0AHgkQXOU3xZGDZpjl1-S07dtgjIvumMrR9">https://ieeexplore.ieee.org/abstract/document/5510913?casa_token=hYekQX0-bnIAAAAA:TIlYOLsXVRkH26cMlJC3ZRyP1LxsEGBSnkNGqCVwu0AHgkQXOU3xZGDZpjl1-S07dtgjIvumMrR9</a></li>
</ul>

</body>
</html>
